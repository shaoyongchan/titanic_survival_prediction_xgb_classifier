{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdbd5ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import ShuffleSplit, GridSearchCV\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61f37484",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading and combining available data\n",
    "train_data = pd.read_csv(\"train_data.csv\")\n",
    "test_data = pd.read_csv(\"test_data.csv\")\n",
    "all_data = pd.concat([train_data, test_data], sort = True).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68cadeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 12 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Age       1046 non-null   float64\n",
      " 1   Embarked  1307 non-null   object \n",
      " 2   Fare      1308 non-null   float64\n",
      " 3   Parch     1309 non-null   int64  \n",
      " 4   Pclass    1309 non-null   int64  \n",
      " 5   Sex       1309 non-null   object \n",
      " 6   SibSp     1309 non-null   int64  \n",
      " 7   Survived  891 non-null    float64\n",
      " 8   Family    1309 non-null   int64  \n",
      " 9   Farepp    1308 non-null   float64\n",
      " 10  Letter    1309 non-null   object \n",
      " 11  Group     1309 non-null   int64  \n",
      "dtypes: float64(4), int64(5), object(3)\n",
      "memory usage: 122.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#feature creation\n",
    "all_data[\"Family\"] = all_data[\"SibSp\"] + all_data[\"Parch\"] + 1\n",
    "all_data[\"Farepp\"] = all_data[\"Fare\"] / all_data[\"Family\"]\n",
    "all_data[\"Letter\"] = [str(cabin)[0] for cabin in all_data[\"Cabin\"]]\n",
    "all_data[\"Group\"] = [all_data.groupby([\"Ticket\"]).count()[\"PassengerId\"].loc[ticket] for ticket in all_data[\"Ticket\"]]\n",
    "\n",
    "all_data.drop([\"Cabin\", \"PassengerId\", \"Name\", \"Ticket\"], axis = 1, inplace = True)\n",
    "all_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "634e17f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Age Embarked  Fare  Parch  Pclass   Sex  SibSp  Survived  Family  \\\n",
      "1043  60.5        S   NaN      0       3  male      0       NaN       1   \n",
      "\n",
      "      Farepp Letter  Group  \n",
      "1043     NaN      n      1  \n",
      "      Age Embarked  Fare  Parch  Pclass     Sex  SibSp  Survived  Family  \\\n",
      "61   38.0      NaN  80.0      0       1  female      0       1.0       1   \n",
      "829  62.0      NaN  80.0      0       1  female      0       1.0       1   \n",
      "\n",
      "     Farepp Letter  Group  \n",
      "61     80.0      B      2  \n",
      "829    80.0      B      2  \n",
      "      Age Embarked     Fare  Parch  Pclass     Sex  SibSp  Survived  Family  \\\n",
      "5     NaN        Q   8.4583      0       3    male      0       0.0       1   \n",
      "17    NaN        S  13.0000      0       2    male      0       1.0       1   \n",
      "19    NaN        C   7.2250      0       3  female      0       1.0       1   \n",
      "26    NaN        C   7.2250      0       3    male      0       0.0       1   \n",
      "28    NaN        Q   7.8792      0       3  female      0       1.0       1   \n",
      "...   ...      ...      ...    ...     ...     ...    ...       ...     ...   \n",
      "1299  NaN        Q   7.7208      0       3  female      0       NaN       1   \n",
      "1301  NaN        Q   7.7500      0       3  female      0       NaN       1   \n",
      "1304  NaN        S   8.0500      0       3    male      0       NaN       1   \n",
      "1307  NaN        S   8.0500      0       3    male      0       NaN       1   \n",
      "1308  NaN        C  22.3583      1       3    male      1       NaN       3   \n",
      "\n",
      "         Farepp Letter  Group  \n",
      "5      8.458300      n      1  \n",
      "17    13.000000      n      1  \n",
      "19     7.225000      n      1  \n",
      "26     7.225000      n      1  \n",
      "28     7.879200      n      1  \n",
      "...         ...    ...    ...  \n",
      "1299   7.720800      n      1  \n",
      "1301   7.750000      n      1  \n",
      "1304   8.050000      n      1  \n",
      "1307   8.050000      n      1  \n",
      "1308   7.452767      n      3  \n",
      "\n",
      "[263 rows x 12 columns]\n",
      "       Age Embarked     Fare  Parch  Pclass     Sex  SibSp  Survived  Family  \\\n",
      "0     22.0        S   7.2500      0       3    male      1       0.0       2   \n",
      "2     26.0        S   7.9250      0       3  female      0       1.0       1   \n",
      "4     35.0        S   8.0500      0       3    male      0       0.0       1   \n",
      "5      NaN        Q   8.4583      0       3    male      0       0.0       1   \n",
      "7      2.0        S  21.0750      1       3    male      3       0.0       5   \n",
      "...    ...      ...      ...    ...     ...     ...    ...       ...     ...   \n",
      "1303  28.0        S   7.7750      0       3  female      0       NaN       1   \n",
      "1304   NaN        S   8.0500      0       3    male      0       NaN       1   \n",
      "1306  38.5        S   7.2500      0       3    male      0       NaN       1   \n",
      "1307   NaN        S   8.0500      0       3    male      0       NaN       1   \n",
      "1308   NaN        C  22.3583      1       3    male      1       NaN       3   \n",
      "\n",
      "        Farepp Letter  Group  \n",
      "0     3.625000      n      1  \n",
      "2     7.925000      n      1  \n",
      "4     8.050000      n      1  \n",
      "5     8.458300      n      1  \n",
      "7     4.215000      n      5  \n",
      "...        ...    ...    ...  \n",
      "1303  7.775000      n      1  \n",
      "1304  8.050000      n      1  \n",
      "1306  7.250000      n      1  \n",
      "1307  8.050000      n      1  \n",
      "1308  7.452767      n      3  \n",
      "\n",
      "[1014 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "#overview of missing data\n",
    "print(all_data[all_data[\"Fare\"].isna()])\n",
    "print(all_data[all_data[\"Embarked\"].isna()])\n",
    "print(all_data[all_data[\"Age\"].isna()])\n",
    "print(all_data[all_data[\"Letter\"] == \"n\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30659438",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputing missing fares data\n",
    "def fare(indices):\n",
    "    for index in indices:\n",
    "        all_data.loc[index, \"Farepp\"] = all_data.groupby([\"Pclass\", \"Family\"])[\"Farepp\"].median()[all_data.loc[index, \"Pclass\"]][all_data.loc[index, \"Family\"]]\n",
    "        all_data.loc[index, \"Fare\"] = all_data.loc[index, \"Farepp\"] * all_data.loc[index, \"Family\"]\n",
    "    return all_data\n",
    "fare_indices = all_data[all_data[\"Fare\"].isna()].index\n",
    "all_data = fare(fare_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "976a196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputing missing embarked data\n",
    "def embarked(indices):\n",
    "    for index in indices:\n",
    "        all_data.loc[index, \"Embarked\"] = all_data.groupby([\"Survived\", \"Pclass\"])[\"Embarked\"].agg(pd.Series.mode)[all_data.loc[index, \"Survived\"]][all_data.loc[index, \"Pclass\"]]\n",
    "    return all_data\n",
    "embarked_indices = all_data[all_data[\"Embarked\"].isna()].index\n",
    "all_data = embarked(embarked_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98799832",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputing missing age data\n",
    "def age(indices):\n",
    "    for index in indices:\n",
    "        all_data.loc[index, \"Age\"] = all_data.groupby([\"Sex\", \"Pclass\"])[\"Age\"].median()[all_data.loc[index, \"Sex\"]][all_data.loc[index, \"Pclass\"]]\n",
    "    return all_data\n",
    "age_indices = all_data[all_data[\"Age\"].isna()].index\n",
    "all_data = age(age_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "270eafd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputing missing cabin data\n",
    "def letter(indices):\n",
    "    for index in indices:\n",
    "        all_data.loc[index, \"Letter\"] = all_data.groupby([\"Sex\", \"Pclass\"])[\"Letter\"].agg(pd.Series.mode)[all_data.loc[index, \"Sex\"]][all_data.loc[index, \"Pclass\"]]\n",
    "    return all_data\n",
    "letter_indices = all_data[all_data[\"Letter\"] == \"n\"].index\n",
    "all_data = letter(letter_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e6e9a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding object data types\n",
    "all_data[\"Sex\"] = LabelEncoder().fit_transform(all_data[\"Sex\"])\n",
    "all_data[\"Embarked\"] = LabelEncoder().fit_transform(all_data[\"Embarked\"])\n",
    "all_data[\"Letter\"] = LabelEncoder().fit_transform(all_data[\"Letter\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9e3a3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 12 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Age       1309 non-null   float64\n",
      " 1   Embarked  1309 non-null   int32  \n",
      " 2   Fare      1309 non-null   float64\n",
      " 3   Parch     1309 non-null   int64  \n",
      " 4   Pclass    1309 non-null   int64  \n",
      " 5   Sex       1309 non-null   int32  \n",
      " 6   SibSp     1309 non-null   int64  \n",
      " 7   Survived  891 non-null    float64\n",
      " 8   Family    1309 non-null   int64  \n",
      " 9   Farepp    1309 non-null   float64\n",
      " 10  Letter    1309 non-null   int32  \n",
      " 11  Group     1309 non-null   int64  \n",
      "dtypes: float64(4), int32(3), int64(5)\n",
      "memory usage: 107.5 KB\n"
     ]
    }
   ],
   "source": [
    "#overview of processed data\n",
    "all_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6a3463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating train and test data\n",
    "train_data = all_data[all_data[\"Survived\"].notna()]\n",
    "test_data = all_data[all_data[\"Survived\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14397572",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating features and target\n",
    "X = train_data.drop([\"Survived\"], axis = 1)\n",
    "y = train_data[\"Survived\"]\n",
    "X_test = test_data.drop([\"Survived\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "462d25f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1.2, 'lambda': 15, 'learning_rate': 0.07, 'n_estimators': 110}\n",
      "0.8402234636871508\n"
     ]
    }
   ],
   "source": [
    "#hyperparameter tuning\n",
    "model = XGBClassifier(max_depth = 7)\n",
    "cv = ShuffleSplit(n_splits = 5, test_size = 0.2)\n",
    "grid = {\"n_estimators\": [103, 105, 107, 110, 114], \"alpha\": [0.5, 0.75, 1, 1.2], \"lambda\": [9, 12, 15, 17], \"learning_rate\": [0.06, 0.07, 0.08, 0.1]}\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = grid, cv = cv, n_jobs = -1)\n",
    "grid_search.fit(X, y)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57a9c7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "final_model = XGBClassifier(n_estimators = grid_search.best_params_[\"n_estimators\"], max_depth = 7, alpha = grid_search.best_params_[\"alpha\"], reg_lambda = grid_search.best_params_[\"lambda\"], learning_rate = grid_search.best_params_[\"learning_rate\"]).fit(X, y)\n",
    "predictions = final_model.predict(X_test)\n",
    "predictions_df = pd.DataFrame({\"PassengerId\": range(892, 1310), \"Survived\": predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8789fdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number: 418\n",
      "Survived: 141\n",
      "Survival rate: 0.3373205741626794\n"
     ]
    }
   ],
   "source": [
    "#checks\n",
    "l = len(predictions_df)\n",
    "s = sum(predictions_df[\"Survived\"])\n",
    "p = s/l\n",
    "\n",
    "print(\"Total number:\", l)\n",
    "print(\"Survived:\", s)\n",
    "print(\"Survival rate:\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40677182",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uploading to csv\n",
    "predictions_df.to_csv(\"titanic_survival_prediction_xgb_classifier_predictions.csv\", sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ca3c33",
   "metadata": {},
   "source": [
    "Accuracy of model: 77.751%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
